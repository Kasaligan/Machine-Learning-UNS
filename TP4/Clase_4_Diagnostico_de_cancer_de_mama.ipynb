{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clase 4 - Diagnostico de cancer de mama",
      "provenance": [],
      "authorship_tag": "ABX9TyOEtXISpggcM4hs56YOw5Gs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kasaligan/Machine-Learning-UNS/blob/main/TP4/Clase_4_Diagnostico_de_cancer_de_mama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw-o40B39zbi"
      },
      "source": [
        "\n",
        "#Breast Cancer Diagnostic o Diagnóstico de cáncer de mama\n",
        "\n",
        "El objetivo de este proyecto es construir un modelo capaz de predecir el diagnóstico de tejidos de cáncer de mama como malignos o benignos. Las características se calculan a partir de una imagen digitalizada de un aspirado con aguja fina (FNA, por sus siglas en inglés) de una masa mamaria. Describen características de los núcleos celulares presentes en la imagen. Distribución de clases: 357 benignas, 212 malignas. Más información sobre este conjunto de datos aquí\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9q0lavJ9vi8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "e831c5c7-a23b-451d-e8ee-6fc379ef8c1d"
      },
      "source": [
        "import pandas as pd\n",
        "cancer_tissues = pd.read_csv(\"https://raw.githubusercontent.com/emmanueliarussi/DataScienceCapstone/master/3_MidtermProjects/ProjectBCD/data/data.csv\")\n",
        "cancer_tissues.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 716
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q_rS5_VTcGY"
      },
      "source": [
        "#Objetivo\n",
        "\n",
        "Para este analisis apunto a implementar el modelo de perceptrones. Claramente no se reinventa la rueda, por lo que utilizo los modulos de sklearn.\n",
        "El modulo de sklearn que implementa perceptrones ya incluye \"boosting\", teniendo un parametro para determinar las epocas. Los parametros estan en el siguiente link: \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html\n",
        "\n",
        "Algo que no implementa el modulo de perceptron por si mismo es el \"bagging\". Para esto utilizare el modulo ensemble, el cual incluye un metodo que nos hara la vida mas facil. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
        "\n",
        "Deseo implementar entonces tres diseños:\n",
        "\n",
        "1.   Perceptrones con una sola epoca).\n",
        "2.   Perceptrones multi-epoca.\n",
        "3.   Bagging con perceptrones multi-epoca.\n",
        "\n",
        "Lo que espero ver es un aumento en la performance a medida que añadimos mas metodos al modelo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Ere2C8Sm7M"
      },
      "source": [
        "#CODIGO GENERAL \n",
        "\n",
        "Comienzo con el codigo importando librerias de interes. Para algunas de las tareas que realizaba de forma manual en los trabajos anteriores descubri que existen librerias con funciones listas para implementar gracias a este video: https://www.youtube.com/watch?v=oLane_Vh3CU\n",
        "\n",
        "Por otro lado encontre modulos de sklearn que computan exactitud, precision, f-measure y demas en sklearn.metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EVt_LONj5W9"
      },
      "source": [
        "import numpy as np  \n",
        "from sklearn.model_selection import train_test_split  #modulo para hacer la separacion de datos\n",
        "from sklearn.linear_model import Perceptron     \n",
        "from sklearn.ensemble import BaggingClassifier      \n",
        "import sklearn.metrics as skm\n",
        "import matplotlib.pyplot as plt\n",
        "import random "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emVNHjwstCkG"
      },
      "source": [
        "Pense en filtrar primero los datos que consideraba con distribuciones concentradas, pero considerando que es un examen medico y la informacion brindada es considerada relevante para el analisis lo mejor seria analizar el dataset completo. \n",
        "\n",
        "A continuacion aislo la columna \"diagnosis\" que sera nuestro target. Descarto la columna \"ID\" que no contiene informacion relevante, y la columna \"Unnamed: 32\" que dios sabra porque esta ahi. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "OvEQJQX2tgTf",
        "outputId": "585cb168-fa3f-43dd-bb49-34180eefc02a"
      },
      "source": [
        "target = cancer_tissues.loc[:,'diagnosis']\n",
        "data = cancer_tissues.drop(['diagnosis', 'id','Unnamed: 32'], axis=1)\n",
        "\n",
        "#Para comprobar veo los primeros elementos del dataset\n",
        "target.head()     \n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 718
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK7bdxkatgcH"
      },
      "source": [
        "Como el objetivo es comparar el desempeño de los diseños deberan tener los mismos datasets de entrenamiento y testeo. Ademas, incluyo una semilla para que todos partan del mismo lugar y sigan el mismo camino a medida que avanzan las iteraciones. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsImfCVIxSBI"
      },
      "source": [
        "test_size=0.5   #fraccion del dataset que se usa para testeo\n",
        "[data_train,data_test,target_train,target_test] = train_test_split(data,target,test_size=test_size)\n",
        "random_state=random.randint(0,1000000)   #Con esto todos los modelos tendran la misma semilla, aunque cambiara en cada ejecucion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrDboVPG081B"
      },
      "source": [
        "##Modelo 1 \n",
        "\n",
        "A continuacion implemento perceptrones. Ya que el dataset de entrenamiento esta completo no hay batchs, y por lo tanto el numero de epocas es igual al numero de iteraciones. \n",
        "Hay muchos argumentos para jugar con la implementacion, pero como desconozco la mayoria me abstengo de copiar sin entender y juego con los mas basicos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC7YqEed3WrZ",
        "outputId": "c6aab9ba-c7ed-48be-f913-74db145df529"
      },
      "source": [
        "max_iter=1  #numero de epocas\n",
        "eta0=1  #constante para multiplicar las updates: mientras menor es mas preciso sera el resultado final pero requerira mas iteraciones para converger\n",
        "\n",
        "ppn = Perceptron(max_iter=max_iter , eta0=eta0, random_state=random_state)   #creo el modelo\n",
        "mod_1=ppn.fit(data_train,target_train)    #entreno el modelo\n",
        "prediccion_1=mod_1.predict(data_test)     #guardo las predicciones del modelo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0rzst7KBS0f"
      },
      "source": [
        "A continuacion evaluo el modelo para ver exactitud, precision y f-measure. \n",
        "\n",
        "Para el calculo de precision y f-measure importa saber cual es el caso positivo y cual el negativo. Esto se informa a traves de labels (etiquetas predichas) y pos_label (caso positivo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-3VIgBOBk9s",
        "outputId": "f5dab955-2b3e-4329-c9fe-163acdc6013b"
      },
      "source": [
        "labels=['B','M']  #etiquetas target\n",
        "pos_label='M'     #target positivo\n",
        "\n",
        "exact_1=skm.accuracy_score(target_test,prediccion_1)  #calculo exactitud\n",
        "prec_1=skm.precision_score(target_test,prediccion_1,labels=labels,pos_label=pos_label)  #calculo precision\n",
        "f_1=skm.f1_score(target_test,prediccion_1,labels=labels,pos_label=pos_label)            #calculo f-measure\n",
        "\n",
        "print(\"Exactitud: \",exact_1,\"\\nPrecision: \",prec_1,\"\\nF-measure: \",f_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exactitud:  0.8350877192982457 \n",
            "Precision:  0.7394366197183099 \n",
            "F-measure:  0.8171206225680935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAkGNPEvGgZ_"
      },
      "source": [
        "##MODELO 2\n",
        "\n",
        "Repito los pasos anteriores con una diferencia: cambio el numero de epocas de 1 a 500. \n",
        "\n",
        "Pense en implementar lo siguiente, sin embargo, no lo implemente. Dejo escrito lo que puse antes y al final comento porque no lo hice.\n",
        "\n",
        "\"(...) Para evitar procesamiento innecesario invoco tres parametros extra al modelo: \n",
        "\n",
        "1.  *early_stopping* : permite que se interrumpan las epocas antes de llegar al maximo determinado. Para esto separa una fraccion de los datos de entrenamiento para hacer una evaluacion al final de cada epoca. Si la performance no mejora un determinado porcentaje en \"n\" iteraciones el proceso se detiene y se queda con el ultimo modelo procesado.\n",
        "2.   *validation_fraction* : porcentaje de los datos de entrenamiento a separar para la validacion.\n",
        "3.   *tol* : tolerancia que se evalua para interrumpir las iteraciones. No termino de comprender a que se refiere. Segun uno de los resultados de busqueda la tolerancia cambia su significado dependiendo de que modelo se este utilizando (perceptrones, lvm, etc) por lo que dejo este parametro en su valor estandar (aunque esta fuertemente relacionado con la interrupcion de las iteraciones).\n",
        "4. *n_iter_no_change* : numero de iteraciones en la cual se interrumpe el procedimiento si no mejora el modelo en una cantidad mayor a *tol*. (...) \"\n",
        "\n",
        "La razon por la que decidi no implementarlo es porque el dataset es relativamente pequeño y no creo que una division de datos para una validacion sea lo optimo en este caso. Por lo tanto implementare el numero de iteraciones que deseo sin validacion integrada.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWWprm8_KSnu"
      },
      "source": [
        "max_iter=1000  #numero de epocas\n",
        "\n",
        "#en este caso podria hacer eta0 menor pues tengo mas iteraciones y asi tendre mejores resultados, pero deseo comparar por lo que lo dejo como era\n",
        "\n",
        "ppn = Perceptron(max_iter=max_iter , eta0=eta0, random_state=random_state)  #creo el modelo\n",
        "mod_2=ppn.fit(data_train,target_train)    #entreno el modelo \n",
        "prediccion_2=mod_2.predict(data_test)     #guardo las predicciones del modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS5EV1nHLqN_"
      },
      "source": [
        "A continuacion evaluo el modelo para ver exactitud, precision y f-measure. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N_hdIN1LqOA",
        "outputId": "0d5114c7-297c-49f8-ed5d-9bfa78d35bec"
      },
      "source": [
        "exact_2=skm.accuracy_score(target_test,prediccion_2)  #calculo exactitud\n",
        "prec_2=skm.precision_score(target_test,prediccion_2,labels=labels,pos_label=pos_label)  #calculo precision\n",
        "f_2=skm.f1_score(target_test,prediccion_2,labels=labels,pos_label=pos_label)            #calculo f-measure\n",
        "\n",
        "print(\"Exactitud: \",exact_2,\"\\nPrecision: \",prec_2,\"\\nF-measure: \",f_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exactitud:  0.8807017543859649 \n",
            "Precision:  0.813953488372093 \n",
            "F-measure:  0.860655737704918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wsZVSc6MdbP"
      },
      "source": [
        "##MODELO 3\n",
        "\n",
        "En este punto cambian un poco las cosas. Para seleccion como clasificador base para el *bagging* un perceptron pero sin random_state. Ya que la idea es que los modelos sean distintos, dejare que la semilla sea determinada aleatoriamente. Luego indico la cantidad de estimadores paralelos que diseñara."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9o5B-wyPpZY"
      },
      "source": [
        "base_estimator=Perceptron(max_iter=max_iter , eta0=eta0)   #eta0 y max_iter se definieron en el modelo 2 \n",
        "n_estimators=10       #pondre 10 perceptrones en paralelo\n",
        "\n",
        "bpnn=BaggingClassifier(base_estimator=base_estimator, n_estimators=n_estimators) #creo el modelo bpnn: bagging perceptron\n",
        "mod_3=bpnn.fit(data_train,target_train)   #entreno el modelo\n",
        "prediccion_3=mod_3.predict(data_test)     #guardo las predicciones del modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkB4wRvDQn9Z"
      },
      "source": [
        "A continuacion evaluo el modelo para ver exactitud, precision y f-measure. \n",
        "\n",
        "Para el calculo de precision y f-measure importa saber cual es el caso positivo y cual el negativo. Esto se informa a traves de labels (etiquetas predichas) y pos_label (caso positivo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ2a3EjrQn9a",
        "outputId": "5b3abcc1-f9fa-4afa-c81f-217731bca5e8"
      },
      "source": [
        "exact_3=skm.accuracy_score(target_test,prediccion_3)  #calculo exactitud\n",
        "prec_3=skm.precision_score(target_test,prediccion_3,labels=labels,pos_label=pos_label)  #calculo precision\n",
        "f_3=skm.f1_score(target_test,prediccion_3,labels=labels,pos_label=pos_label)            #calculo f-measure\n",
        "\n",
        "print(\"Exactitud: \",exact_3,\"\\nPrecision: \",prec_3,\"\\nF-measure: \",f_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exactitud:  0.9157894736842105 \n",
            "Precision:  0.9690721649484536 \n",
            "F-measure:  0.8867924528301888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD0p0bY0RKtw"
      },
      "source": [
        "#CONCLUSIONES\n",
        "\n",
        "Presento los resultados de los tres diseños. Recordemos antes de seguir las caracteristicas de los modelos:\n",
        "1. El modelo 1 es un diseño por perceptron de una sola epoca.\n",
        "2. El modelo 2 es un diseño por perceptron de 1000 epocas.\n",
        "3. El modelo 3 es un diseño \"bagging\" con base de perceptron que entrena 10 perceptrones de 1000 eras en paralelo y luego entrega una prediccion segun mayoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qod6Ge5Tdpy",
        "outputId": "61e6e78a-d18c-4d2c-8649-db38e1b14207"
      },
      "source": [
        "print(\"MODELO 1 - Exactitud: \",round(exact_1,5),\"\\tPrecision: \",round(prec_1,5),\"\\tF-measure: \",round(f_1,5))\n",
        "print(\"MODELO 2 - Exactitud: \",round(exact_2,5),\"\\tPrecision: \",round(prec_2,5),\"\\tF-measure: \",round(f_2,5))\n",
        "print(\"MODELO 3 - Exactitud: \",round(exact_3,5),\"\\tPrecision: \",round(prec_3,5),\"\\tF-measure: \",round(f_3,5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODELO 1 - Exactitud:  0.83509 \tPrecision:  0.73944 \tF-measure:  0.81712\n",
            "MODELO 2 - Exactitud:  0.8807 \tPrecision:  0.81395 \tF-measure:  0.86066\n",
            "MODELO 3 - Exactitud:  0.91579 \tPrecision:  0.96907 \tF-measure:  0.88679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORxct4zYTS3x"
      },
      "source": [
        "\n",
        "\n",
        "Luego de probar algunas veces observo que, en general, se cumple en todas las estadisticas que:\n",
        "\n",
        "Modelo 3 > Modelo 2 > Modelo 1.\n",
        "\n",
        "Existen algunos casos (raros) en los que el modelo 2 se comporta peor que el modelo 1. Esto podria ser debido al split de los datos aunque no tengo seguridad en esa explicacion. De todas formas el modelo 3 se comporta consistentemente mejor que los otros dos (salvo aún mas raras excepciones)."
      ]
    }
  ]
}